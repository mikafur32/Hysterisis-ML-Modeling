{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from keras import mixed_precision\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "TODO: memory management!!! \n",
    "\n",
    "'''\n",
    "from keras import backend as K\n",
    "\n",
    "#os.chdir(\".\\\\lib\")\n",
    "#print(os.getcwd())\n",
    "\n",
    "#import models_base\n",
    "\n",
    "\n",
    "import models_cuda\n",
    "import ingest, predict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only allocate 13GB of memory on the first GPU\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*6)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "\n",
    "mixed_precision.set_global_policy(\n",
    "    policy\n",
    ")\n",
    "\n",
    "## FLAGS ##\n",
    "# RAS model output or USGS\n",
    "USGS_FLAG = True\n",
    "\n",
    "### HENRY RAS ###\n",
    "csv = r\"..\\data\\Henry_WSS_2017_2023.csv\"\n",
    "columns = {'Q': 'Discharge', 'WSS': 'Slope'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS\n",
    "1. WSS\t        | Q\n",
    "2. V\t        | Q\n",
    "3. WL\t        | Q\n",
    "4. WSS, V\t    | Q\n",
    "5. WSS, WL\t    | Q\n",
    "6. WSS, V, WL\t| Q\n",
    "6. WSS\t        | WL\n",
    "7. V\t        | WL\n",
    "8. Q\t        | WL\n",
    "9. WSS, V  \t    | WL\n",
    "10. WSS, Q\t    | WL\n",
    "11. WSS, V, Q\t| WL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSS_Q = {\"target\": \"Q\", \"features\": { \"WSS\": \"WSS\"}}\n",
    "\n",
    "WL_Q = {\"target\": \"Q\", \"features\": { \"WL\": \"WL\"}}\n",
    "\n",
    "WSSWL_Q = {\"target\": \"Q\", \"features\": { \"WSS\": \"WSS\", \"WL\": \"WL\"}}\n",
    "\n",
    "WSS_WL = {\"target\": \"WL\", \"features\": { \"WSS\": \"WSS\"}}\n",
    "\n",
    "Q_WL = {\"target\": \"WL\", \"features\": { \"Q\": \"Q\"}}\n",
    "\n",
    "WSSQ_WL = {\"target\": \"WL\", \"features\": { \"WSS\": \"WSS\", \"Q\": \"Q\"}}\n",
    "\n",
    "\n",
    "tests= [WSS_Q,WL_Q,WSSWL_Q,WSS_WL,Q_WL,WSSQ_WL ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = datetime.now().strftime(\"%B_%d_%Y_%H_%M\")\n",
    "\n",
    "\n",
    "target = \"Discharge\"\n",
    "data_name = \"Henry_RAS_2017_2023_\" + f\"cuda_testing\"#\"{date}\"\n",
    "\n",
    "\n",
    "train_range = [\"1/1/2017 0:00\",\"12/31/2021 23:45\"]\n",
    "test_range = [\"1/1/2022 0:00\", \"12/31/2022 23:45\"]\n",
    "train_scaled, test_scaled, train_dates, test_dates, all_dates, scaler = ingest.ingest(csv, target, renames= columns, USGS_FLAG=USGS_FLAG, train_range= train_range, test_range= test_range)#train_test_ratio= 0.8)\n",
    "trainX, trainY = ingest.reshape(train_scaled)#, timestep_type= \"hr\")\n",
    "testX, testY = ingest.reshape(test_scaled)#, timestep_type= \"hr\")\n",
    "\n",
    "\n",
    "model_names = ['Basic_LSTM', \"GRU\", 'Bidirectional_LSTM', 'Stacked_LSTM']\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = models_cuda.prebuilt_models(model_name, trainX, trainY, epochs= 10, batch_size=32, loss= \"nse\", load_models=False, data= data_name)\n",
    "    validation_loss = models_cuda.evaluate_model(model, testX, testY)\n",
    "    models_cuda.plot_model(model_name, validation_loss, data_name)\n",
    "    K.clear_session()\n",
    "\n",
    "'''\n",
    "tstart = '2022-03-18 00:00:00'\n",
    "tend = '2022-04-07 00:00:00'\n",
    "'''\n",
    "\n",
    "tstart = \"3/18/2022 0:00\"\n",
    "tend = \"4/7/2022 23:45\"\n",
    "event_range = [tstart, tend]\n",
    "\n",
    "for model_name in model_names:\n",
    "    predicts = predict.predict(model_name, testX, data_name)\n",
    "    predict.plot_predicts(model_name, predicts, testY, test_dates, data_name, event_range= event_range, event_plotstep= \"Day\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WSS_Q = {\"target\": \"Q\", \"features\": { \"WSS\": \"WSS\"}, \"Name\": \"Q_WSS\"}\n",
    "\n",
    "WL_Q = {\"target\": \"Q\", \"features\": { \"WL\": \"WL\"}, \"Name\": \"Q_WL\"}\n",
    "\n",
    "WSSWL_Q = {\"target\": \"Q\", \"features\": { \"WSS\": \"WSS\", \"WL\": \"WL\"}, \"Name\": \"Q_WSS-WL\"}\n",
    "\n",
    "WSS_WL = {\"target\": \"WL\", \"features\": { \"WSS\": \"WSS\"}, \"Name\": \"WL_WSS\"}\n",
    "\n",
    "Q_WL = {\"target\": \"WL\", \"features\": { \"Q\": \"Q\"}, \"Name\": \"WL_Q\"}\n",
    "\n",
    "WSSQ_WL = {\"target\": \"WL\", \"features\": { \"WSS\": \"WSS\", \"Q\": \"Q\"}, \"Name\": \"WL_WSS-Q\"}\n",
    "\n",
    "\n",
    "tests= [WSS_Q,WL_Q,WSSWL_Q,WSS_WL,Q_WL,WSSQ_WL ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    dataname= \"Henry_RAS_2017_2023_\" + f\"{test['Name']}\"\n",
    "\n",
    "    predicts = predict.predict(model_name, testX, data_name)\n",
    "    \n",
    "        \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(feature_maps[0, :, :], annot=False, cmap='viridis')\n",
    "    plt.ylabel('Timestep')\n",
    "    plt.xlabel('Feature Map Index')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "usage: tensorboard [-h] [--helpfull] {serve,dev} ...\n",
       "tensorboard: error: unrecognized arguments: C:\\Users\\Mikey\\Documents\\Github\\Hysterisis-ML-Modeling\\lib\\logs\\Henry_RAS_2017_2023_Q_WSS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard serve --logdir= \"C:\\Users\\Mikey\\Documents\\Github\\Hysterisis-ML-Modeling\\lib\\logs\\Henry_RAS_2017_2023_Q_WSS\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 0).\n",
       "Contents of stdout:\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--detect_file_replacement BOOL]\n",
       "                   {serve,dev} ...\n",
       "\n",
       "TensorBoard is a suite of web applications for inspecting and understanding\n",
       "your TensorFlow runs and graphs. https://github.com/tensorflow/tensorboard\n",
       "\n",
       "positional arguments:\n",
       "  {serve,dev}           TensorBoard subcommand (defaults to 'serve')\n",
       "    serve               start local TensorBoard server (default subcommand)\n",
       "    dev                 upload data to TensorBoard.dev\n",
       "\n",
       "options:\n",
       "  -h, --help            show this help message and exit\n",
       "  --helpfull            show full help message and exit\n",
       "  --logdir PATH         Directory where TensorBoard will look to find\n",
       "                        TensorFlow event files that it can display.\n",
       "                        TensorBoard will recursively walk the directory\n",
       "                        structure rooted at logdir, looking for .*tfevents.*\n",
       "                        files. A leading tilde will be expanded with the\n",
       "                        semantics of Python's os.expanduser function.\n",
       "  --logdir_spec PATH_SPEC\n",
       "                        Like `--logdir`, but with special interpretation for\n",
       "                        commas and colons: commas separate multiple runs,\n",
       "                        where a colon specifies a new name for a run. For\n",
       "                        example: `tensorboard --logdir_spec=name1:/path/to/log\n",
       "                        s/1,name2:/path/to/logs/2`. This flag is discouraged\n",
       "                        and can usually be avoided. TensorBoard walks log\n",
       "                        directories recursively; for finer-grained control,\n",
       "                        prefer using a symlink tree. Some features may not\n",
       "                        work when using `--logdir_spec` instead of `--logdir`.\n",
       "  --host ADDR           What host to listen to (default: localhost). To serve\n",
       "                        to the entire local network on both IPv4 and IPv6, see\n",
       "                        `--bind_all`, with which this option is mutually\n",
       "                        exclusive.\n",
       "  --bind_all            Serve on all public interfaces. This will expose your\n",
       "                        TensorBoard instance to the network on both IPv4 and\n",
       "                        IPv6 (where available). Mutually exclusive with\n",
       "                        `--host`.\n",
       "  --port PORT           Port to serve TensorBoard on. Pass 0 to request an\n",
       "                        unused port selected by the operating system, or pass\n",
       "                        \"default\" to try to bind to the default port (6006)\n",
       "                        but search for a nearby free port if the default port\n",
       "                        is unavailable. (default: \"default\").\n",
       "  --reuse_port BOOL     Enables the SO_REUSEPORT option on the socket opened\n",
       "                        by TensorBoard's HTTP server, for platforms that\n",
       "                        support it. This is useful in cases when a parent\n",
       "                        process has obtained the port already and wants to\n",
       "                        delegate access to the port to TensorBoard as a\n",
       "                        subprocess.(default: False).\n",
       "  --load_fast {false,auto,true}\n",
       "                        Use alternate mechanism to load data. Typically 100x\n",
       "                        faster or more, but only available on some platforms\n",
       "                        and invocations. Defaults to \"auto\" to use this new\n",
       "                        mode only if available, otherwise falling back to the\n",
       "                        legacy loading path. Set to \"true\" to suppress the\n",
       "                        advisory note and hard-fail if the fast codepath is\n",
       "                        not available. Set to \"false\" to always fall back.\n",
       "                        Feedback/issues:\n",
       "                        https://github.com/tensorflow/tensorboard/issues/4784\n",
       "                        (default: auto)\n",
       "  --extra_data_server_flags EXTRA_DATA_SERVER_FLAGS\n",
       "                        Experimental. With `--load_fast`, pass these\n",
       "                        additional command-line flags to the data server.\n",
       "                        Subject to POSIX word splitting per `shlex.split`.\n",
       "                        Meant for debugging; not officially supported.\n",
       "  --grpc_creds_type {local,ssl,ssl_dev}\n",
       "                        Experimental. The type of credentials to use to\n",
       "                        connect to the data server. (default: local)\n",
       "  --grpc_data_provider PORT\n",
       "                        Experimental. Address of a gRPC server exposing a data\n",
       "                        provider. Set to empty string to disable. (default: )\n",
       "  --purge_orphaned_data BOOL\n",
       "                        Whether to purge data that may have been orphaned due\n",
       "                        to TensorBoard restarts. Setting\n",
       "                        --purge_orphaned_data=False can be used to debug data\n",
       "                        disappearance. (default: True)\n",
       "  --db URI              [experimental] sets SQL database URI and enables DB\n",
       "                        backend mode, which is read-only unless --db_import is\n",
       "                        also passed.\n",
       "  --db_import           [experimental] enables DB read-and-import mode, which\n",
       "                        in combination with --logdir imports event files into\n",
       "                        a DB backend on the fly. The backing DB is temporary\n",
       "                        unless --db is also passed to specify a DB path to\n",
       "                        use.\n",
       "  --inspect             Prints digests of event files to command line. This is\n",
       "                        useful when no data is shown on TensorBoard, or the\n",
       "                        data shown looks weird. Must specify one of `logdir`\n",
       "                        or `event_file` flag. Example usage: `tensorboard\n",
       "                        --inspect --logdir mylogdir --tag loss` See tensorboar\n",
       "                        d/backend/event_processing/event_file_inspector.py for\n",
       "                        more info.\n",
       "  --version_tb          Prints the version of Tensorboard\n",
       "  --tag TAG             tag to query for; used with --inspect\n",
       "  --event_file PATH     The particular event file to query for. Only used if\n",
       "                        --inspect is present and --logdir is not specified.\n",
       "  --path_prefix PATH    An optional, relative prefix to the path, e.g.\n",
       "                        \"/path/to/tensorboard\". resulting in the new base url\n",
       "                        being located at localhost:6006/path/to/tensorboard\n",
       "                        under default settings. A leading slash is required\n",
       "                        when specifying the path_prefix. A trailing slash is\n",
       "                        optional and has no effect. The path_prefix can be\n",
       "                        leveraged for path based routing of an ELB when the\n",
       "                        website base_url is not available e.g.\n",
       "                        \"example.site.com/path/to/tensorboard/\".\n",
       "  --window_title TEXT   changes title of browser window\n",
       "  --max_reload_threads COUNT\n",
       "                        The max number of threads that TensorBoard can use to\n",
       "                        reload runs. Not relevant for db read-only mode. Each\n",
       "                        thread reloads one run at a time. (default: 1)\n",
       "  --reload_interval SECONDS\n",
       "                        How often the backend should load more data, in\n",
       "                        seconds. Set to 0 to load just once at startup. Must\n",
       "                        be non-negative. (default: 5.0)\n",
       "  --reload_task TYPE    [experimental] The mechanism to use for the background\n",
       "                        data reload task. The default \"auto\" option will\n",
       "                        conditionally use threads for legacy reloading and a\n",
       "                        child process for DB import reloading. The \"process\"\n",
       "                        option is only useful with DB import mode. The\n",
       "                        \"blocking\" option will block startup until reload\n",
       "                        finishes, and requires --load_interval=0. (default:\n",
       "                        auto)\n",
       "  --reload_multifile BOOL\n",
       "                        [experimental] If true, this enables experimental\n",
       "                        support for continuously polling multiple event files\n",
       "                        in each run directory for newly appended data (rather\n",
       "                        than only polling the last event file). Event files\n",
       "                        will only be polled as long as their most recently\n",
       "                        read data is newer than the threshold defined by\n",
       "                        --reload_multifile_inactive_secs, to limit resource\n",
       "                        usage. Beware of running out of memory if the logdir\n",
       "                        contains many active event files. (default: false)\n",
       "  --reload_multifile_inactive_secs SECONDS\n",
       "                        [experimental] Configures the age threshold in seconds\n",
       "                        at which an event file that has no event wall time\n",
       "                        more recent than that will be considered an inactive\n",
       "                        file and no longer polled (to limit resource usage).\n",
       "                        If set to -1, no maximum age will be enforced, but\n",
       "                        beware of running out of memory and heavier filesystem\n",
       "                        read traffic. If set to 0, this reverts to the older\n",
       "                        last-file-only polling strategy (akin to\n",
       "                        --reload_multifile=false). (default: 86400 - intended\n",
       "                        to ensure an event file remains active if it receives\n",
       "                        new data at least once per 24 hour period)\n",
       "  --generic_data TYPE   [experimental] Hints whether plugins should read from\n",
       "                        generic data provider infrastructure. For plugins that\n",
       "                        support only the legacy multiplexer APIs or only the\n",
       "                        generic data APIs, this option has no effect. The\n",
       "                        \"auto\" option enables this only for plugins that are\n",
       "                        considered to have stable support for generic data\n",
       "                        providers. (default: auto)\n",
       "  --samples_per_plugin SAMPLES_PER_PLUGIN\n",
       "                        An optional comma separated list of\n",
       "                        plugin_name=num_samples pairs to explicitly specify\n",
       "                        how many samples to keep per tag for that plugin. For\n",
       "                        unspecified plugins, TensorBoard randomly downsamples\n",
       "                        logged summaries to reasonable values to prevent out-\n",
       "                        of-memory errors for long running jobs. This flag\n",
       "                        allows fine control over that downsampling. Note that\n",
       "                        if a plugin is not specified in this list, a plugin-\n",
       "                        specific default number of samples will be enforced.\n",
       "                        (for example, 10 for images, 500 for histograms, and\n",
       "                        1000 for scalars). Most users should not need to set\n",
       "                        this flag.\n",
       "  --detect_file_replacement BOOL\n",
       "                        [experimental] If true, this enables experimental\n",
       "                        support for detecting when event files are replaced\n",
       "                        with new versions that contain additional data. This\n",
       "                        is not needed in the normal case where new data is\n",
       "                        either appended to an existing file or written to a\n",
       "                        brand new file, but it arises, for example, when using\n",
       "                        rsync without the --inplace option, in which new\n",
       "                        versions of the original file are first written to a\n",
       "                        temporary file, then swapped into the final location.\n",
       "                        This option is currently incompatible with\n",
       "                        --load_fast=true, and if passed will disable fast-\n",
       "                        loading mode. (default: false)\n",
       "\n",
       "absl.app:\n",
       "  -?,--[no]help: show this help\n",
       "    (default: 'false')\n",
       "  --[no]helpfull: show full help\n",
       "    (default: 'false')\n",
       "  --[no]helpshort: show this help\n",
       "    (default: 'false')\n",
       "  --[no]helpxml: like --helpfull, but generates XML output\n",
       "    (default: 'false')\n",
       "  --[no]only_check_args: Set to true to validate args and exit.\n",
       "    (default: 'false')\n",
       "  --[no]pdb: Alias for --pdb_post_mortem.\n",
       "    (default: 'false')\n",
       "  --[no]pdb_post_mortem: Set to true to handle uncaught exceptions with PDB post\n",
       "    mortem.\n",
       "    (default: 'false')\n",
       "  --profile_file: Dump profile information to a file (for python -m pstats).\n",
       "    Implies --run_with_profiling.\n",
       "  --[no]run_with_pdb: Set to true for PDB debug mode\n",
       "    (default: 'false')\n",
       "  --[no]run_with_profiling: Set to true for profiling the script. Execution will\n",
       "    be slower, and the output format might change over time.\n",
       "    (default: 'false')\n",
       "  --[no]use_cprofile_for_profiling: Use cProfile instead of the profile module\n",
       "    for profiling. This has no effect unless --run_with_profiling is set.\n",
       "    (default: 'true')\n",
       "\n",
       "absl.logging:\n",
       "  --[no]alsologtostderr: also log to stderr?\n",
       "    (default: 'false')\n",
       "  --log_dir: directory to write logfiles into\n",
       "    (default: '')\n",
       "  --logger_levels: Specify log level of loggers. The format is a CSV list of\n",
       "    `name:level`. Where `name` is the logger name used with\n",
       "    `logging.getLogger()`, and `level` is a level name  (INFO, DEBUG, etc). e.g.\n",
       "    `myapp.foo:INFO,other.logger:DEBUG`\n",
       "    (default: '')\n",
       "  --[no]logtostderr: Should only log to stderr?\n",
       "    (default: 'false')\n",
       "  --[no]showprefixforinfo: If False, do not prepend prefix to info messages when\n",
       "    it's logged to stderr, --verbosity is set to INFO level, and python logging\n",
       "    is used.\n",
       "    (default: 'true')\n",
       "  --stderrthreshold: log messages at this level, or more severe, to stderr in\n",
       "    addition to the logfile.  Possible values are 'debug', 'info', 'warning',\n",
       "    'error', and 'fatal'.  Obsoletes --alsologtostderr. Using --alsologtostderr\n",
       "    cancels the effect of this flag. Please also note that this flag is subject\n",
       "    to --verbosity and requires logfile not be stderr.\n",
       "    (default: 'fatal')\n",
       "  -v,--verbosity: Logging verbosity level. Messages logged at this level or\n",
       "    lower will be included. Set to 1 for debug logging. If the flag was not set\n",
       "    or supplied, the value will be changed from the default of -1 (warning) to 0\n",
       "    (info) after flags are parsed.\n",
       "    (default: '-1')\n",
       "    (an integer)\n",
       "\n",
       "absl.testing.absltest:\n",
       "  --test_random_seed: Random seed for testing. Some test frameworks may change\n",
       "    the default value of this flag between runs, so it is not appropriate for\n",
       "    seeding probabilistic tests.\n",
       "    (default: '301')\n",
       "    (an integer)\n",
       "  --test_randomize_ordering_seed: If positive, use this as a seed to randomize\n",
       "    the execution order for test cases. If \"random\", pick a random seed to use.\n",
       "    If 0 or not set, do not randomize test case execution order. This flag also\n",
       "    overrides the TEST_RANDOMIZE_ORDERING_SEED environment variable.\n",
       "    (default: '')\n",
       "  --test_srcdir: Root of directory tree where source files live\n",
       "    (default: '')\n",
       "  --test_tmpdir: Directory for temporary testing files\n",
       "    (default: 'C:\\\\Users\\\\Mikey\\\\AppData\\\\Local\\\\Temp\\\\absl_testing')\n",
       "  --xml_output_file: File to store XML test results\n",
       "    (default: '')\n",
       "\n",
       "tensorflow.python.ops.parallel_for.pfor:\n",
       "  --[no]op_conversion_fallback_to_while_loop: DEPRECATED: Flag is ignored.\n",
       "    (default: 'true')\n",
       "\n",
       "tensorflow.python.tpu.client.client:\n",
       "  --[no]hbm_oom_exit: Exit the script when the TPU HBM is OOM.\n",
       "    (default: 'true')\n",
       "  --[no]runtime_oom_exit: Exit the script when the TPU runtime is OOM.\n",
       "    (default: 'true')\n",
       "\n",
       "tensorflow.python.tpu.tensor_tracer_flags:\n",
       "  --delta_threshold: Log if history based diff crosses this threshold.\n",
       "    (default: '0.5')\n",
       "    (a number)\n",
       "  --[no]tt_check_filter: Terminate early to check op name filtering.\n",
       "    (default: 'false')\n",
       "  --[no]tt_single_core_summaries: Report single core metric and avoid\n",
       "    aggregation.\n",
       "    (default: 'false')\n",
       "\n",
       "absl.flags:\n",
       "  --flagfile: Insert flag definitions from the given file into the command line.\n",
       "    (default: '')\n",
       "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
       "    the command line even if the program does not define a flag with that name.\n",
       "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
       "    format.\n",
       "    (default: '')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=C:\\Users\\Mikey\\Documents\\Github\\Hysterisis-ML-Modeling\\lib\\logs\\Henry_RAS_2017_2023_Q_WSS  --helpfull --port= 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 0).\n",
       "Contents of stdout:\n",
       "2.10.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MeselheResearchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
